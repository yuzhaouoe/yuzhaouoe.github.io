var store = [{
        "title": "LogitLens from scratch with Hugging Face Transformers",
        "excerpt":"In this short tutorial, we’ll implement LogitLens to inspect the inner representations of a pre-trained Phi-1.5. LogitLens is a straightforward yet effective interpretability method.   The core idea behind it is to apply the language model’s output layer (also known as the “unembedding matrix” or “language modeling head”) to the hidden states at each layer of the transformer. This allows us to see how the model’s internal representations change as the input progresses through the network. Surprisingly, the model often acquires a significant amount of semantic understanding in the earlier layers of the transformer. By inspecting the predicted tokens at each layer, we can observe how the model’s understanding of the input evolves.      Disclaimer: ✋ If you’re looking for advanced interpretability tools, there are plenty of powerful libraries out there. But here, we’re going back to basics and do this from scratch because it’s always cool to understand how things work under the hood.    You can also    We’ll use Microsoft Phi-1.5 here since it’s a small, open model. Feel free to swap in another Hugging Face model.   from transformers import AutoModelForCausalLM, AutoTokenizer import torch  model_id= \"microsoft/phi-1.5\"  # load the model model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).eval().to(device) tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, bos_token='&lt;bos&gt;', use_fast=False)  Downloading the model might take a while, so you better pick a small model :). Let’s now consider an example input sentence and tokenize it.   example = \"The quick brown fox jumps over the lazy\" inputs = tokenizer(example, return_tensors=\"pt\").to(device)  print(\"Input shape: \", inputs[\"input_ids\"].shape)  Input shape:  torch.Size([1, 9])   The sentence was encoded into 9 tokens. In case you want to know what the tokens looks like, you can just decode them back:   original_input_tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0], skip_special_tokens=False) print(\"Input tokens: \", original_input_tokens)   Input tokens:  ['&lt;bos&gt;', 'The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy']   As we can see, the tokenizer added the beggining of sentence &lt;bos&gt; token. The ugly Ġ represent spaces.   In the notebook you can find a function clean these up a bit (I find the Ġs are really annoying):  original_input_tokens = cleanup_tokens(original_input_tokens) original_input_tokens  ['&lt;bos&gt;', 'The', ' quick', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy']   Now, let’s feed the input into the model to get the next token prediction along with all the hidden states. Fortunately, the model’s forward method provides an option to return its hidden states.   # we need all the intermediate hidden states with torch.no_grad():     outputs = model(**inputs, output_hidden_states=True)  # # print(outputs.keys()) print(\"Logits shape: \", outputs[\"logits\"].shape)  Logits shape:  torch.Size([1, 9, 51200]) # (batch, sequence len, vocab size)   The logits have been already projected into the vocabulary space. Hidden states on the other hand are still “raw” token representations. We’ll have one hiddent state vector for each model layer.   hidden_states = outputs.hidden_states print(\"Number of model layers\", len(hidden_states)) print(\"Hidden states for first layer\", hidden_states[0].shape)  Number of model layers:  25 Hidden states for first layer:  torch.Size([1, 9, 2048])   As we see, each layer in the model produces a hidden state. Here the last dimension represents the embedding size (not the vocbulary size).   By applying the language modeling head (or unembedding matrix) to the hidden state at any layer, we can generate ‘early’ logits—predictions from intermediate representations. While the model isn’t explicitly trained to produce meaningful logits at these layers, we’ll see that it naturally starts embedding token-level information along the way.   We can apply the language modeling head like this:   logits_at_second_layer = model.lm_head(hidden_states[2]) print(\"Logits at second layer shape: \", logits_at_second_layer.shape)  Logits at second layer shape:  torch.Size([1, 9, 51200])   We now want to access the hidden state at each layer, apply the language modeling head to get the logits, and finally decode the logits into tokens.   for i, hidden_state in enumerate(hidden_states):     # apply the language model head to the hidden states     logits = model.lm_head(hidden_state)      # decode the logits to get the predicted token ids     predicted_token_ids = logits.argmax(-1)      # convert the token ids to tokens     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)     predicted_tokens = cleanup_tokens(predicted_tokens)      # append the predicted tokens to the list for later     logitlens.append(predicted_tokens)      print(f\"Layer {i}: {predicted_tokens}\")   Layer 0: ['-', ' S', '-', '-', '-', '-', '-', ' S', '-'] Layer 1: ['ed', 'oret', 'est', 'ies', 'es', 'uit', ' the', ' same', ' double'] Layer 2: ['import', 'oret', 'est', 'ies', 'es', 'uits', ' time', ' same', ' part'] Layer 3: ['import', 'orem', 'est', 'arf', 'es', 'es', ' all', ' entire', ' man'] Layer 4: [' realise', 'orem', 'est', 'arf', 'es', 'uit', 'worked', ' entire', ' man'] Layer 5: [' realise', 'orem', 'est', 'arf', 'es', 'uit', 'worked', ' entire', ' man'] Layer 6: [' realise', 'orem', 'est', 'arf', 'es', 'uit', 'kill', 'ses', ' man'] Layer 7: ['iveness', 'orem', 'est', ' fox', 'es', 'ers', ' all', ' entire', ' brown'] Layer 8: ['iveness', 'orem', 'ness', ' fox', 'es', 'ers', 'ind', ' entire', ' poor'] Layer 9: ['iveness', 'orem', 'ness', ' fox', 'es', 'ers', ' obstacles', ' entire', ' poor'] Layer 10: ['iveness', 'orem', 'ness', ' ph', 'es', 'ers', ' obstacles', ' entire', ' poor'] Layer 11: ['iveness', 'orem', ' brown', ' fox', 'es', 'ers', ' obstacles', ' entire', ' poor'] Layer 12: ['iveness', 'oret', ' brown', ' fox', 'es', ' into', ' obstacles', ' entire', ' poor'] Layer 13: ['ality', 'oret', ' brown', ' fox', 'es', ' into', ' obstacles', ' entire', ' poor'] Layer 14: ['ality', 'ory', ' brown', ' ph', 'es', ' into', ' obstacles', ' entire', ' poor'] Layer 15: ['iveness', 'ory', ' brown', ' fox', 'es', ' into', ' obstacles', ' entire', ' poor'] Layer 16: ['import', 'ory', ' brown', ' fox', 'es', ' into', ' lazy', ' entire', ' poor'] Layer 17: ['import', 'mes', ' brown', ' fox', 'es', ' over', ' the', ' lazy', ' poor'] Layer 18: ['import', ' first', ' brown', ' fox', 'es', ' over', ' the', ' lazy', ' dog'] Layer 19: [' example', ' first', ' brown', 'Ċ', 'es', ' over', ' the', ' lazy', ' dog'] Layer 20: ['ĊĊ', ' first', ' brown', 's', 'es', ' over', ' the', ' lazy', ' dog'] Layer 21: ['ing', ' first', ' brown', ' fox', 'es', ' over', ' the', ' lazy', ' dog'] Layer 22: ['Ċ', ' first', ' brown', 'Ċ', ' jumps', ' over', ' the', ' lazy', ' dog'] Layer 23: ['Ċ', 'Ċ', ' brown', ' fox', ' J', ' over', ' the', ' lazy', ' dog'] Layer 24: ['Ċ', 'ory', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy', ' dog']   As you observe, the predictions refine layer-by-layer, reflecting the model’s gradual understanding of the input. We can visualize the predictions with a heatmap:   # create a heatmap that has a row for each list in the logitlens list import matplotlib.pyplot as plt import seaborn as sns import numpy as np  sns.set_theme(style=\"white\")  # just for the bkg color intensities = np.ones((len(hidden_states), len(original_input_tokens)))  # Create heatmap plt.figure(figsize=(20, 10)) ax = sns.heatmap(intensities[::2],                 annot=cleanup_tokens(logitlens)[::2],                 fmt='',                 cmap='Greys',                 xticklabels=original_input_tokens,                 yticklabels=list(range(len(logitlens)))[::2],                 cbar=False                 ).invert_yaxis()       Right now, our heatmap just displays the model’s top predictions (using argmax), which is fine but a bit flat. Let’s make it more interesting by incorporating model certainty into the visualization.   A good way to quantify the model’s certainity about its output is looking at the entropy of the output distribution. Let’s replace the background color of each cell with the entropy of the model when generating that token.   We’ll calculate the entropy of the output distribution, using it to color the background:   # aux function to compute the entropy from logits def entropy_from_logits(logits):     probs = torch.nn.functional.softmax(logits, dim=-1).clamp(1e-8, 1) #avoid nans     return -torch.sum(probs * torch.log(probs), dim=-1).squeeze()   Now we can run the same code as before, this time we’ll also compute and store the entropies.   logitlens = [] entropies = []  for i, hidden_state in enumerate(hidden_states):     # apply the language model head to the hidden states     logits = model.lm_head(hidden_state)      # get the entropy of the logits     entropy = entropy_from_logits(logits).float().cpu().detach().numpy()      # decode the logits to get the predicted token ids     predicted_token_ids = logits.argmax(-1)      # convert the token ids to tokens     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)     predicted_tokens = cleanup_tokens(predicted_tokens)      # append the predicted tokens to the list     logitlens.append(predicted_tokens)     entropies.append(entropy)      print(f\"Layer {i}: {predicted_tokens}\")   Let’s now create a plot where each cell is colored based on the entropy.   # Create figure and axis plt.figure(figsize=(20, 10))  # Create heatmap ax = sns.heatmap(np.stack(entropies)[::2],                 annot=logitlens[::2],                 fmt='',                 cmap='YlGnBu',                 xticklabels=original_input_tokens,                 yticklabels=list(range(len(logitlens)))[::2],                 ).invert_yaxis()      Hope you liked this! If you have any suggestions/questios, feel free to drop me a message/email or visit my page or my twitter @devoto_alessio.  ","categories": [],
        "tags": [],
        "url": "/LogitLens/",
        "teaser": null
      },{
    "title": "Page Not Found",
    "excerpt":"Sorry, but the page you were trying to view does not exist.  ","url": "http://0.0.0.0:4007/404.html"
  },{
    "title": "",
    "excerpt":"I am a third-year PhD student at the University of Edinburgh (start from Sept. 2023), a member of EdinburghNLP, supervised by Pasquale Minervini and Mirella Lapata. I interned at Microsfot Research Cambridge in 2025.   My research interests include 1) improving reasoning and perception capabilities of AI in open-ended systems; and 2) enhancing efficiency and faithfulness of black-box models by mechanistic interpretability methods.   Selected Works   Learning GUI Grounding with Spatial Reasoning from Visual Feedback  Yu Zhao, Wei-Ning Chen, Huseyin Atahan Inan, Samuel Kessler, Lu Wang, Lukas Wutschitz, Fangkai Yang, Chaoyun Zhang, Pasquale Minervini, Saravan Rajmohan, Robert Sim  Preprint, 2025   MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly  Zhaowei Wang, Wenhao Yu, Xiyu Ren, Jipeng Zhang, Yu Zhao, Rohit Saxena, Liang Cheng, Ginny Wong, Simon See, Pasquale Minervini, Yangqiu Song, Mark Steedman  NeurIPS 2025, Spotlight   Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering  Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini  NAACL 2025, Oral   A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression  Alessio Devoto*, Yu Zhao*, Simone Scardapane, Pasquale Minervini  EMNLP 2024, Oral   Analysing The Impact of Sequence Composition on Language Model Pre-Training  Yu Zhao, Yuanbin Qu, Konrad Staniszewski, Szymon Tworkowski, Wei Liu, Piotr Miłoś, Yuxiang Wu, Pasquale Minervini  ACL 2024, Oral   Structured Packing in LLM Training Improves Long Context Utilization  Konrad Staniszewski, Szymon Tworkowski, Sebastian Jaszczur, Yu Zhao, Henryk Michalewski, Łukasz Kuciński, Piotr Miłoś  AAAI 2025, Oral   Are We Done with MMLU?  Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini  NAACL 2025     Check out all my publications in Google Scholar or Semantic Scholar.            ","url": "http://0.0.0.0:4007/"
  },{
    "title": null,
    "excerpt":"var idx = lunr(function () {\r   this.field('title')\r   this.field('excerpt')\r   this.field('categories')\r   this.field('tags')\r   this.ref('id')\r \r   this.pipeline.remove(lunr.trimmer)\r \r   for (var item in store) {\r     this.add({\r       title: store[item].title,\r       excerpt: store[item].excerpt,\r       categories: store[item].categories,\r       tags: store[item].tags,\r       id: item\r     })\r   }\r });\r \r $(document).ready(function() {\r   $('input#search').on('keyup', function () {\r     var resultdiv = $('#results');\r     var query = $(this).val().toLowerCase();\r     var result =\r       idx.query(function (q) {\r         query.split(lunr.tokenizer.separator).forEach(function (term) {\r           q.term(term, { boost: 100 })\r           if(query.lastIndexOf(\" \") != query.length-1){\r             q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })\r           }\r           if (term != \"\"){\r             q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })\r           }\r         })\r       });\r     resultdiv.empty();\r     resultdiv.prepend(''+result.length+' Result(s) found ');\r     for (var item in result) {\r       var ref = result[item].ref;\r       if(store[ref].teaser){\r         var searchitem =\r           ''+\r             ''+\r               ''+\r                 ''+store[ref].title+''+\r               ' '+\r               ''+\r                 ''+\r               ''+\r               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+\r             ''+\r           '';\r       }\r       else{\r     \t  var searchitem =\r           ''+\r             ''+\r               ''+\r                 ''+store[ref].title+''+\r               ' '+\r               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+\r             ''+\r           '';\r       }\r       resultdiv.append(searchitem);\r     }\r   });\r });\r ","url": "http://0.0.0.0:4007/assets/js/lunr/lunr-en.js"
  },{
    "title": null,
    "excerpt":"step1list = new Array();\r step1list[\"ΦΑΓΙΑ\"] = \"ΦΑ\";\r step1list[\"ΦΑΓΙΟΥ\"] = \"ΦΑ\";\r step1list[\"ΦΑΓΙΩΝ\"] = \"ΦΑ\";\r step1list[\"ΣΚΑΓΙΑ\"] = \"ΣΚΑ\";\r step1list[\"ΣΚΑΓΙΟΥ\"] = \"ΣΚΑ\";\r step1list[\"ΣΚΑΓΙΩΝ\"] = \"ΣΚΑ\";\r step1list[\"ΟΛΟΓΙΟΥ\"] = \"ΟΛΟ\";\r step1list[\"ΟΛΟΓΙΑ\"] = \"ΟΛΟ\";\r step1list[\"ΟΛΟΓΙΩΝ\"] = \"ΟΛΟ\";\r step1list[\"ΣΟΓΙΟΥ\"] = \"ΣΟ\";\r step1list[\"ΣΟΓΙΑ\"] = \"ΣΟ\";\r step1list[\"ΣΟΓΙΩΝ\"] = \"ΣΟ\";\r step1list[\"ΤΑΤΟΓΙΑ\"] = \"ΤΑΤΟ\";\r step1list[\"ΤΑΤΟΓΙΟΥ\"] = \"ΤΑΤΟ\";\r step1list[\"ΤΑΤΟΓΙΩΝ\"] = \"ΤΑΤΟ\";\r step1list[\"ΚΡΕΑΣ\"] = \"ΚΡΕ\";\r step1list[\"ΚΡΕΑΤΟΣ\"] = \"ΚΡΕ\";\r step1list[\"ΚΡΕΑΤΑ\"] = \"ΚΡΕ\";\r step1list[\"ΚΡΕΑΤΩΝ\"] = \"ΚΡΕ\";\r step1list[\"ΠΕΡΑΣ\"] = \"ΠΕΡ\";\r step1list[\"ΠΕΡΑΤΟΣ\"] = \"ΠΕΡ\";\r step1list[\"ΠΕΡΑΤΑ\"] = \"ΠΕΡ\";\r step1list[\"ΠΕΡΑΤΩΝ\"] = \"ΠΕΡ\";\r step1list[\"ΤΕΡΑΣ\"] = \"ΤΕΡ\";\r step1list[\"ΤΕΡΑΤΟΣ\"] = \"ΤΕΡ\";\r step1list[\"ΤΕΡΑΤΑ\"] = \"ΤΕΡ\";\r step1list[\"ΤΕΡΑΤΩΝ\"] = \"ΤΕΡ\";\r step1list[\"ΦΩΣ\"] = \"ΦΩ\";\r step1list[\"ΦΩΤΟΣ\"] = \"ΦΩ\";\r step1list[\"ΦΩΤΑ\"] = \"ΦΩ\";\r step1list[\"ΦΩΤΩΝ\"] = \"ΦΩ\";\r step1list[\"ΚΑΘΕΣΤΩΣ\"] = \"ΚΑΘΕΣΤ\";\r step1list[\"ΚΑΘΕΣΤΩΤΟΣ\"] = \"ΚΑΘΕΣΤ\";\r step1list[\"ΚΑΘΕΣΤΩΤΑ\"] = \"ΚΑΘΕΣΤ\";\r step1list[\"ΚΑΘΕΣΤΩΤΩΝ\"] = \"ΚΑΘΕΣΤ\";\r step1list[\"ΓΕΓΟΝΟΣ\"] = \"ΓΕΓΟΝ\";\r step1list[\"ΓΕΓΟΝΟΤΟΣ\"] = \"ΓΕΓΟΝ\";\r step1list[\"ΓΕΓΟΝΟΤΑ\"] = \"ΓΕΓΟΝ\";\r step1list[\"ΓΕΓΟΝΟΤΩΝ\"] = \"ΓΕΓΟΝ\";\r \r v = \"[ΑΕΗΙΟΥΩ]\";\r v2 = \"[ΑΕΗΙΟΩ]\"\r \r function stemWord(w) {\r   var stem;\r   var suffix;\r   var firstch;\r   var origword = w;\r   test1 = new Boolean(true);\r \r   if(w.length '+result.length+' Result(s) found ');\r     for (var item in result) {\r       var ref = result[item].ref;\r       if(store[ref].teaser){\r         var searchitem =\r           ''+\r             ''+\r               ''+\r                 ''+store[ref].title+''+\r               ' '+\r               ''+\r                 ''+\r               ''+\r               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+\r             ''+\r           '';\r       }\r       else{\r     \t  var searchitem =\r           ''+\r             ''+\r               ''+\r                 ''+store[ref].title+''+\r               ' '+\r               ''+store[ref].excerpt.split(\" \").splice(0,20).join(\" \")+'... '+\r             ''+\r           '';\r       }\r       resultdiv.append(searchitem);\r     }\r   });\r });\r ","url": "http://0.0.0.0:4007/assets/js/lunr/lunr-gr.js"
  },{
    "title": null,
    "excerpt":"var store = [\r   {%- for c in site.collections -%}\r     {%- if forloop.last -%}\r       {%- assign l = true -%}\r     {%- endif -%}\r     {%- assign docs = c.docs | where_exp:'doc','doc.search != false' -%}\r     {%- for doc in docs -%}\r       {%- if doc.header.teaser -%}\r         {%- capture teaser -%}{{ doc.header.teaser }}{%- endcapture -%}\r       {%- else -%}\r         {%- assign teaser = site.teaser -%}\r       {%- endif -%}\r       {\r         \"title\": {{ doc.title | jsonify }},\r         \"excerpt\":\r           {%- if site.search_full_content == true -%}\r             {{ doc.content | newline_to_br |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \"|\r             strip_html | strip_newlines | jsonify }},\r           {%- else -%}\r             {{ doc.content | newline_to_br |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \" |\r               replace:\" \", \" \"|\r             strip_html | strip_newlines | truncatewords: 50 | jsonify }},\r           {%- endif -%}\r         \"categories\": {{ doc.categories | jsonify }},\r         \"tags\": {{ doc.tags | jsonify }},\r         \"url\": {{ doc.url | relative_url | jsonify }},\r         \"teaser\": {{ teaser | relative_url | jsonify }}\r       }{%- unless forloop.last and l -%},{%- endunless -%}\r     {%- endfor -%}\r   {%- endfor -%}{%- if site.lunr.search_within_pages -%},\r   {%- assign pages = site.pages | where_exp:'doc','doc.search != false' -%}\r   {%- for doc in pages -%}\r     {%- if forloop.last -%}\r       {%- assign l = true -%}\r     {%- endif -%}\r   {\r     \"title\": {{ doc.title | jsonify }},\r     \"excerpt\":\r         {%- if site.search_full_content == true -%}\r           {{ doc.content | newline_to_br |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \"|\r           strip_html | strip_newlines | jsonify }},\r         {%- else -%}\r           {{ doc.content | newline_to_br |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \" |\r             replace:\" \", \" \"|\r           strip_html | strip_newlines | truncatewords: 50 | jsonify }},\r         {%- endif -%}\r       \"url\": {{ doc.url | absolute_url | jsonify }}\r   }{%- unless forloop.last and l -%},{%- endunless -%}\r   {%- endfor -%}\r {%- endif -%}]\r ","url": "http://0.0.0.0:4007/assets/js/lunr/lunr-store.js"
  },{
    "title": null,
    "excerpt":" {% if page.xsl %} {% endif %} {% assign collections = site.collections | where_exp:'collection','collection.output != false' %}{% for collection in collections %}{% assign docs = collection.docs | where_exp:'doc','doc.sitemap != false' %}{% for doc in docs %} {{ doc.url | replace:'/index.html','/' | absolute_url | xml_escape }} {% if doc.last_modified_at or doc.date %}{{ doc.last_modified_at | default: doc.date | date_to_xmlschema }} {% endif %} {% endfor %}{% endfor %}{% assign pages = site.html_pages | where_exp:'doc','doc.sitemap != false' | where_exp:'doc','doc.url != \"/404.html\"' %}{% for page in pages %} {{ page.url | replace:'/index.html','/' | absolute_url | xml_escape }} {% if page.last_modified_at %}{{ page.last_modified_at | date_to_xmlschema }} {% endif %} {% endfor %}{% assign static_files = page.static_files | where_exp:'page','page.sitemap != false' | where_exp:'page','page.name != \"404.html\"' %}{% for file in static_files %} {{ file.path | replace:'/index.html','/' | absolute_url | xml_escape }} {{ file.modified_time | date_to_xmlschema }}  {% endfor %} ","url": "http://0.0.0.0:4007/sitemap.xml"
  },{
    "title": null,
    "excerpt":"Sitemap: {{ \"sitemap.xml\" | absolute_url }} ","url": "http://0.0.0.0:4007/robots.txt"
  },{
    "title": null,
    "excerpt":"{% if page.xsl %}{% endif %}Jekyll{{ site.time | date_to_xmlschema }}{{ page.url | absolute_url | xml_escape }}{% assign title = site.title | default: site.name %}{% if page.collection != \"posts\" %}{% assign collection = page.collection | capitalize %}{% assign title = title | append: \" | \" | append: collection %}{% endif %}{% if page.category %}{% assign category = page.category | capitalize %}{% assign title = title | append: \" | \" | append: category %}{% endif %}{% if title %}{{ title | smartify | xml_escape }}{% endif %}{% if site.description %}{{ site.description | xml_escape }}{% endif %}{% if site.author %}{{ site.author.name | default: site.author | xml_escape }}{% if site.author.email %}{{ site.author.email | xml_escape }}{% endif %}{% if site.author.uri %}{{ site.author.uri | xml_escape }}{% endif %}{% endif %}{% if page.tags %}{% assign posts = site.tags[page.tags] %}{% else %}{% assign posts = site[page.collection] %}{% endif %}{% if page.category %}{% assign posts = posts | where: \"category\", page.category %}{% endif %}{% unless site.show_drafts %}{% assign posts = posts | where_exp: \"post\", \"post.draft != true\" %}{% endunless %}{% assign posts = posts | sort: \"date\" | reverse %}{% assign posts_limit = site.feed.posts_limit | default: 10 %}{% for post in posts limit: posts_limit %}{% assign post_title = post.title | smartify | strip_html | normalize_whitespace | xml_escape %}{{ post_title }}{{ post.date | date_to_xmlschema }}{{ post.last_modified_at | default: post.date | date_to_xmlschema }}{{ post.id | absolute_url | xml_escape }}{% assign excerpt_only = post.feed.excerpt_only | default: site.feed.excerpt_only %}{% unless excerpt_only %}{{ post.content | strip | xml_escape }}{% endunless %}{% assign post_author = post.author | default: post.authors[0] | default: site.author %}{% assign post_author = site.data.authors[post_author] | default: post_author %}{% assign post_author_email = post_author.email | default: nil %}{% assign post_author_uri = post_author.uri | default: nil %}{% assign post_author_name = post_author.name | default: post_author %}{{ post_author_name | default: \"\" | xml_escape }}{% if post_author_email %}{{ post_author_email | xml_escape }}{% endif %}{% if post_author_uri %}{{ post_author_uri | xml_escape }}{% endif %}{% if post.category %}{% elsif post.categories %}{% for category in post.categories %}{% endfor %}{% endif %}{% for tag in post.tags %}{% endfor %}{% if post.excerpt and post.excerpt != empty %}{{ post.excerpt | strip_html | normalize_whitespace | xml_escape }}{% endif %}{% assign post_image = post.image.path | default: post.image %}{% if post_image %}{% unless post_image contains \"://\" %}{% assign post_image = post_image | absolute_url %}{% endunless %}{% endif %}{% endfor %}","url": "http://0.0.0.0:4007/feed.xml"
  }]
