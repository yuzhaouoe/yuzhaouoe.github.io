<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en-US" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>LogitLens from scratch with Hugging Face Transformers - Yu Zhao</title>
<meta name="description" content="In this short tutorial, we’ll implement LogitLens to inspect the inner representations of a pre-trained Phi-1.5. LogitLens is a straightforward yet effective interpretability method.  The core idea behind it is to apply the language model’s output layer (also known as the “unembedding matrix” or “language modeling head”) to the hidden states at each layer of the transformer. This allows us to see how the model’s internal representations change as the input progresses through the network. Surprisingly, the model often acquires a significant amount of semantic understanding in the earlier layers of the transformer. By inspecting the predicted tokens at each layer, we can observe how the model’s understanding of the input evolves.     Disclaimer: ✋ If you’re looking for advanced interpretability tools, there are plenty of powerful libraries out there. But here, we’re going back to basics and do this from scratch because it’s always cool to understand how things work under the hood.   You can also   We’ll use Microsoft Phi-1.5 here since it’s a small, open model. Feel free to swap in another Hugging Face model.  from transformers import AutoModelForCausalLM, AutoTokenizer import torch  model_id= &quot;microsoft/phi-1.5&quot;  # load the model model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).eval().to(device) tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, bos_token=&#39;&lt;bos&gt;&#39;, use_fast=False)  Downloading the model might take a while, so you better pick a small model :). Let’s now consider an example input sentence and tokenize it.  example = &quot;The quick brown fox jumps over the lazy&quot; inputs = tokenizer(example, return_tensors=&quot;pt&quot;).to(device)  print(&quot;Input shape: &quot;, inputs[&quot;input_ids&quot;].shape)  Input shape:  torch.Size([1, 9])   The sentence was encoded into 9 tokens. In case you want to know what the tokens looks like, you can just decode them back:  original_input_tokens = tokenizer.convert_ids_to_tokens(inputs[&quot;input_ids&quot;][0], skip_special_tokens=False) print(&quot;Input tokens: &quot;, original_input_tokens)   Input tokens:  [&#39;&lt;bos&gt;&#39;, &#39;The&#39;, &#39;Ġquick&#39;, &#39;Ġbrown&#39;, &#39;Ġfox&#39;, &#39;Ġjumps&#39;, &#39;Ġover&#39;, &#39;Ġthe&#39;, &#39;Ġlazy&#39;]   As we can see, the tokenizer added the beggining of sentence &lt;bos&gt; token. The ugly Ġ represent spaces.  In the notebook you can find a function clean these up a bit (I find the Ġs are really annoying): original_input_tokens = cleanup_tokens(original_input_tokens) original_input_tokens  [&#39;&lt;bos&gt;&#39;, &#39;The&#39;, &#39; quick&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;]   Now, let’s feed the input into the model to get the next token prediction along with all the hidden states. Fortunately, the model’s forward method provides an option to return its hidden states.  # we need all the intermediate hidden states with torch.no_grad():     outputs = model(**inputs, output_hidden_states=True)  # # print(outputs.keys()) print(&quot;Logits shape: &quot;, outputs[&quot;logits&quot;].shape)  Logits shape:  torch.Size([1, 9, 51200]) # (batch, sequence len, vocab size)   The logits have been already projected into the vocabulary space. Hidden states on the other hand are still “raw” token representations. We’ll have one hiddent state vector for each model layer.  hidden_states = outputs.hidden_states print(&quot;Number of model layers&quot;, len(hidden_states)) print(&quot;Hidden states for first layer&quot;, hidden_states[0].shape)  Number of model layers:  25 Hidden states for first layer:  torch.Size([1, 9, 2048])   As we see, each layer in the model produces a hidden state. Here the last dimension represents the embedding size (not the vocbulary size).  By applying the language modeling head (or unembedding matrix) to the hidden state at any layer, we can generate ‘early’ logits—predictions from intermediate representations. While the model isn’t explicitly trained to produce meaningful logits at these layers, we’ll see that it naturally starts embedding token-level information along the way.  We can apply the language modeling head like this:  logits_at_second_layer = model.lm_head(hidden_states[2]) print(&quot;Logits at second layer shape: &quot;, logits_at_second_layer.shape)  Logits at second layer shape:  torch.Size([1, 9, 51200])   We now want to access the hidden state at each layer, apply the language modeling head to get the logits, and finally decode the logits into tokens.  for i, hidden_state in enumerate(hidden_states):     # apply the language model head to the hidden states     logits = model.lm_head(hidden_state)      # decode the logits to get the predicted token ids     predicted_token_ids = logits.argmax(-1)      # convert the token ids to tokens     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)     predicted_tokens = cleanup_tokens(predicted_tokens)      # append the predicted tokens to the list for later     logitlens.append(predicted_tokens)      print(f&quot;Layer {i}: {predicted_tokens}&quot;)   Layer 0: [&#39;-&#39;, &#39; S&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39; S&#39;, &#39;-&#39;] Layer 1: [&#39;ed&#39;, &#39;oret&#39;, &#39;est&#39;, &#39;ies&#39;, &#39;es&#39;, &#39;uit&#39;, &#39; the&#39;, &#39; same&#39;, &#39; double&#39;] Layer 2: [&#39;import&#39;, &#39;oret&#39;, &#39;est&#39;, &#39;ies&#39;, &#39;es&#39;, &#39;uits&#39;, &#39; time&#39;, &#39; same&#39;, &#39; part&#39;] Layer 3: [&#39;import&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;es&#39;, &#39; all&#39;, &#39; entire&#39;, &#39; man&#39;] Layer 4: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;worked&#39;, &#39; entire&#39;, &#39; man&#39;] Layer 5: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;worked&#39;, &#39; entire&#39;, &#39; man&#39;] Layer 6: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;kill&#39;, &#39;ses&#39;, &#39; man&#39;] Layer 7: [&#39;iveness&#39;, &#39;orem&#39;, &#39;est&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; all&#39;, &#39; entire&#39;, &#39; brown&#39;] Layer 8: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39;ind&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 9: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 10: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; ph&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 11: [&#39;iveness&#39;, &#39;orem&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 12: [&#39;iveness&#39;, &#39;oret&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 13: [&#39;ality&#39;, &#39;oret&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 14: [&#39;ality&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; ph&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 15: [&#39;iveness&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 16: [&#39;import&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; lazy&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 17: [&#39;import&#39;, &#39;mes&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; poor&#39;] Layer 18: [&#39;import&#39;, &#39; first&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 19: [&#39; example&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;Ċ&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 20: [&#39;ĊĊ&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;s&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 21: [&#39;ing&#39;, &#39; first&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 22: [&#39;Ċ&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;Ċ&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 23: [&#39;Ċ&#39;, &#39;Ċ&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; J&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 24: [&#39;Ċ&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]   As you observe, the predictions refine layer-by-layer, reflecting the model’s gradual understanding of the input. We can visualize the predictions with a heatmap:  # create a heatmap that has a row for each list in the logitlens list import matplotlib.pyplot as plt import seaborn as sns import numpy as np  sns.set_theme(style=&quot;white&quot;)  # just for the bkg color intensities = np.ones((len(hidden_states), len(original_input_tokens)))  # Create heatmap plt.figure(figsize=(20, 10)) ax = sns.heatmap(intensities[::2],                 annot=cleanup_tokens(logitlens)[::2],                 fmt=&#39;&#39;,                 cmap=&#39;Greys&#39;,                 xticklabels=original_input_tokens,                 yticklabels=list(range(len(logitlens)))[::2],                 cbar=False                 ).invert_yaxis()      Right now, our heatmap just displays the model’s top predictions (using argmax), which is fine but a bit flat. Let’s make it more interesting by incorporating model certainty into the visualization.  A good way to quantify the model’s certainity about its output is looking at the entropy of the output distribution. Let’s replace the background color of each cell with the entropy of the model when generating that token.  We’ll calculate the entropy of the output distribution, using it to color the background:  # aux function to compute the entropy from logits def entropy_from_logits(logits):     probs = torch.nn.functional.softmax(logits, dim=-1).clamp(1e-8, 1) #avoid nans     return -torch.sum(probs * torch.log(probs), dim=-1).squeeze()   Now we can run the same code as before, this time we’ll also compute and store the entropies.  logitlens = [] entropies = []  for i, hidden_state in enumerate(hidden_states):     # apply the language model head to the hidden states     logits = model.lm_head(hidden_state)      # get the entropy of the logits     entropy = entropy_from_logits(logits).float().cpu().detach().numpy()      # decode the logits to get the predicted token ids     predicted_token_ids = logits.argmax(-1)      # convert the token ids to tokens     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)     predicted_tokens = cleanup_tokens(predicted_tokens)      # append the predicted tokens to the list     logitlens.append(predicted_tokens)     entropies.append(entropy)      print(f&quot;Layer {i}: {predicted_tokens}&quot;)   Let’s now create a plot where each cell is colored based on the entropy.  # Create figure and axis plt.figure(figsize=(20, 10))  # Create heatmap ax = sns.heatmap(np.stack(entropies)[::2],                 annot=logitlens[::2],                 fmt=&#39;&#39;,                 cmap=&#39;YlGnBu&#39;,                 xticklabels=original_input_tokens,                 yticklabels=list(range(len(logitlens)))[::2],                 ).invert_yaxis()     Hope you liked this! If you have any suggestions/questios, feel free to drop me a message/email or visit my page or my twitter @devoto_alessio.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Yu Zhao">
<meta property="og:title" content="LogitLens from scratch with Hugging Face Transformers">
<meta property="og:url" content="http://0.0.0.0:4000/LogitLens/">


  <meta property="og:description" content="In this short tutorial, we’ll implement LogitLens to inspect the inner representations of a pre-trained Phi-1.5. LogitLens is a straightforward yet effective interpretability method.  The core idea behind it is to apply the language model’s output layer (also known as the “unembedding matrix” or “language modeling head”) to the hidden states at each layer of the transformer. This allows us to see how the model’s internal representations change as the input progresses through the network. Surprisingly, the model often acquires a significant amount of semantic understanding in the earlier layers of the transformer. By inspecting the predicted tokens at each layer, we can observe how the model’s understanding of the input evolves.     Disclaimer: ✋ If you’re looking for advanced interpretability tools, there are plenty of powerful libraries out there. But here, we’re going back to basics and do this from scratch because it’s always cool to understand how things work under the hood.   You can also   We’ll use Microsoft Phi-1.5 here since it’s a small, open model. Feel free to swap in another Hugging Face model.  from transformers import AutoModelForCausalLM, AutoTokenizer import torch  model_id= &quot;microsoft/phi-1.5&quot;  # load the model model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).eval().to(device) tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, bos_token=&#39;&lt;bos&gt;&#39;, use_fast=False)  Downloading the model might take a while, so you better pick a small model :). Let’s now consider an example input sentence and tokenize it.  example = &quot;The quick brown fox jumps over the lazy&quot; inputs = tokenizer(example, return_tensors=&quot;pt&quot;).to(device)  print(&quot;Input shape: &quot;, inputs[&quot;input_ids&quot;].shape)  Input shape:  torch.Size([1, 9])   The sentence was encoded into 9 tokens. In case you want to know what the tokens looks like, you can just decode them back:  original_input_tokens = tokenizer.convert_ids_to_tokens(inputs[&quot;input_ids&quot;][0], skip_special_tokens=False) print(&quot;Input tokens: &quot;, original_input_tokens)   Input tokens:  [&#39;&lt;bos&gt;&#39;, &#39;The&#39;, &#39;Ġquick&#39;, &#39;Ġbrown&#39;, &#39;Ġfox&#39;, &#39;Ġjumps&#39;, &#39;Ġover&#39;, &#39;Ġthe&#39;, &#39;Ġlazy&#39;]   As we can see, the tokenizer added the beggining of sentence &lt;bos&gt; token. The ugly Ġ represent spaces.  In the notebook you can find a function clean these up a bit (I find the Ġs are really annoying): original_input_tokens = cleanup_tokens(original_input_tokens) original_input_tokens  [&#39;&lt;bos&gt;&#39;, &#39;The&#39;, &#39; quick&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;]   Now, let’s feed the input into the model to get the next token prediction along with all the hidden states. Fortunately, the model’s forward method provides an option to return its hidden states.  # we need all the intermediate hidden states with torch.no_grad():     outputs = model(**inputs, output_hidden_states=True)  # # print(outputs.keys()) print(&quot;Logits shape: &quot;, outputs[&quot;logits&quot;].shape)  Logits shape:  torch.Size([1, 9, 51200]) # (batch, sequence len, vocab size)   The logits have been already projected into the vocabulary space. Hidden states on the other hand are still “raw” token representations. We’ll have one hiddent state vector for each model layer.  hidden_states = outputs.hidden_states print(&quot;Number of model layers&quot;, len(hidden_states)) print(&quot;Hidden states for first layer&quot;, hidden_states[0].shape)  Number of model layers:  25 Hidden states for first layer:  torch.Size([1, 9, 2048])   As we see, each layer in the model produces a hidden state. Here the last dimension represents the embedding size (not the vocbulary size).  By applying the language modeling head (or unembedding matrix) to the hidden state at any layer, we can generate ‘early’ logits—predictions from intermediate representations. While the model isn’t explicitly trained to produce meaningful logits at these layers, we’ll see that it naturally starts embedding token-level information along the way.  We can apply the language modeling head like this:  logits_at_second_layer = model.lm_head(hidden_states[2]) print(&quot;Logits at second layer shape: &quot;, logits_at_second_layer.shape)  Logits at second layer shape:  torch.Size([1, 9, 51200])   We now want to access the hidden state at each layer, apply the language modeling head to get the logits, and finally decode the logits into tokens.  for i, hidden_state in enumerate(hidden_states):     # apply the language model head to the hidden states     logits = model.lm_head(hidden_state)      # decode the logits to get the predicted token ids     predicted_token_ids = logits.argmax(-1)      # convert the token ids to tokens     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)     predicted_tokens = cleanup_tokens(predicted_tokens)      # append the predicted tokens to the list for later     logitlens.append(predicted_tokens)      print(f&quot;Layer {i}: {predicted_tokens}&quot;)   Layer 0: [&#39;-&#39;, &#39; S&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39; S&#39;, &#39;-&#39;] Layer 1: [&#39;ed&#39;, &#39;oret&#39;, &#39;est&#39;, &#39;ies&#39;, &#39;es&#39;, &#39;uit&#39;, &#39; the&#39;, &#39; same&#39;, &#39; double&#39;] Layer 2: [&#39;import&#39;, &#39;oret&#39;, &#39;est&#39;, &#39;ies&#39;, &#39;es&#39;, &#39;uits&#39;, &#39; time&#39;, &#39; same&#39;, &#39; part&#39;] Layer 3: [&#39;import&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;es&#39;, &#39; all&#39;, &#39; entire&#39;, &#39; man&#39;] Layer 4: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;worked&#39;, &#39; entire&#39;, &#39; man&#39;] Layer 5: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;worked&#39;, &#39; entire&#39;, &#39; man&#39;] Layer 6: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;kill&#39;, &#39;ses&#39;, &#39; man&#39;] Layer 7: [&#39;iveness&#39;, &#39;orem&#39;, &#39;est&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; all&#39;, &#39; entire&#39;, &#39; brown&#39;] Layer 8: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39;ind&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 9: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 10: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; ph&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 11: [&#39;iveness&#39;, &#39;orem&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 12: [&#39;iveness&#39;, &#39;oret&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 13: [&#39;ality&#39;, &#39;oret&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 14: [&#39;ality&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; ph&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 15: [&#39;iveness&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 16: [&#39;import&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; lazy&#39;, &#39; entire&#39;, &#39; poor&#39;] Layer 17: [&#39;import&#39;, &#39;mes&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; poor&#39;] Layer 18: [&#39;import&#39;, &#39; first&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 19: [&#39; example&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;Ċ&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 20: [&#39;ĊĊ&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;s&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 21: [&#39;ing&#39;, &#39; first&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 22: [&#39;Ċ&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;Ċ&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 23: [&#39;Ċ&#39;, &#39;Ċ&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; J&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;] Layer 24: [&#39;Ċ&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]   As you observe, the predictions refine layer-by-layer, reflecting the model’s gradual understanding of the input. We can visualize the predictions with a heatmap:  # create a heatmap that has a row for each list in the logitlens list import matplotlib.pyplot as plt import seaborn as sns import numpy as np  sns.set_theme(style=&quot;white&quot;)  # just for the bkg color intensities = np.ones((len(hidden_states), len(original_input_tokens)))  # Create heatmap plt.figure(figsize=(20, 10)) ax = sns.heatmap(intensities[::2],                 annot=cleanup_tokens(logitlens)[::2],                 fmt=&#39;&#39;,                 cmap=&#39;Greys&#39;,                 xticklabels=original_input_tokens,                 yticklabels=list(range(len(logitlens)))[::2],                 cbar=False                 ).invert_yaxis()      Right now, our heatmap just displays the model’s top predictions (using argmax), which is fine but a bit flat. Let’s make it more interesting by incorporating model certainty into the visualization.  A good way to quantify the model’s certainity about its output is looking at the entropy of the output distribution. Let’s replace the background color of each cell with the entropy of the model when generating that token.  We’ll calculate the entropy of the output distribution, using it to color the background:  # aux function to compute the entropy from logits def entropy_from_logits(logits):     probs = torch.nn.functional.softmax(logits, dim=-1).clamp(1e-8, 1) #avoid nans     return -torch.sum(probs * torch.log(probs), dim=-1).squeeze()   Now we can run the same code as before, this time we’ll also compute and store the entropies.  logitlens = [] entropies = []  for i, hidden_state in enumerate(hidden_states):     # apply the language model head to the hidden states     logits = model.lm_head(hidden_state)      # get the entropy of the logits     entropy = entropy_from_logits(logits).float().cpu().detach().numpy()      # decode the logits to get the predicted token ids     predicted_token_ids = logits.argmax(-1)      # convert the token ids to tokens     predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)     predicted_tokens = cleanup_tokens(predicted_tokens)      # append the predicted tokens to the list     logitlens.append(predicted_tokens)     entropies.append(entropy)      print(f&quot;Layer {i}: {predicted_tokens}&quot;)   Let’s now create a plot where each cell is colored based on the entropy.  # Create figure and axis plt.figure(figsize=(20, 10))  # Create heatmap ax = sns.heatmap(np.stack(entropies)[::2],                 annot=logitlens[::2],                 fmt=&#39;&#39;,                 cmap=&#39;YlGnBu&#39;,                 xticklabels=original_input_tokens,                 yticklabels=list(range(len(logitlens)))[::2],                 ).invert_yaxis()     Hope you liked this! If you have any suggestions/questios, feel free to drop me a message/email or visit my page or my twitter @devoto_alessio.">







  <meta property="article:published_time" content="2024-10-28T00:00:00+01:00">





  

  


<link rel="canonical" href="http://0.0.0.0:4000/LogitLens/">







  <meta name="google-site-verification" content="dDLCziuVpFsoWUVXwVC9VDkoCSYjI89nDe59V2KFn-g" />






<!-- end _includes/seo.html -->


<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Yu Zhao
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/assets/images/YU_ZHAO_CV_2024_October.pdf"
                
                
              >📝 Résumé</a>
            </li><li class="masthead__menu-item">
              <a
                href="https://huggingface.co/yuzhaouoe"
                
                
              >🤗 Hugging Face</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://0.0.0.0:4000/">
        <img src="/assets/images/yuzhao-avatar.jpg" alt="" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://0.0.0.0:4000/" itemprop="url"></a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Yu Zhao</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Edinburgh, Scotland</span>
        </li>
      

      
        
          
            <li><a href="https://x.com/yuzhaouoe" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-square-x-twitter" aria-hidden="true"></i><span class="label">Twitter</span></a></li>
          
        
          
            <li><a href="mailto:yuzhaouoe@gmail.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/yuzhaouoe" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/yu-zhao-b303482b3/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://scholar.google.com/citations?user=QR0LL6gAAAAJ" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fa-brands fa-google-scholar" aria-hidden="true"></i><span class="label">Google Scholar</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="LogitLens from scratch with Hugging Face Transformers">
    <meta itemprop="description" content="In this short tutorial, we’ll implement LogitLens to inspect the inner representations of a pre-trained Phi-1.5. LogitLens is a straightforward yet effective interpretability method.The core idea behind it is to apply the language model’s output layer (also known as the “unembedding matrix” or “language modeling head”) to the hidden states at each layer of the transformer. This allows us to see how the model’s internal representations change as the input progresses through the network. Surprisingly, the model often acquires a significant amount of semantic understanding in the earlier layers of the transformer. By inspecting the predicted tokens at each layer, we can observe how the model’s understanding of the input evolves.  Disclaimer: ✋ If you’re looking for advanced interpretability tools, there are plenty of powerful libraries out there. But here, we’re going back to basics and do this from scratch because it’s always cool to understand how things work under the hood.You can also We’ll use Microsoft Phi-1.5 here since it’s a small, open model. Feel free to swap in another Hugging Face model.from transformers import AutoModelForCausalLM, AutoTokenizerimport torchmodel_id= &quot;microsoft/phi-1.5&quot;# load the modelmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).eval().to(device)tokenizer = AutoTokenizer.from_pretrained(model_id, add_bos_token=True, bos_token=&#39;&lt;bos&gt;&#39;, use_fast=False)Downloading the model might take a while, so you better pick a small model :).Let’s now consider an example input sentence and tokenize it.example = &quot;The quick brown fox jumps over the lazy&quot;inputs = tokenizer(example, return_tensors=&quot;pt&quot;).to(device)print(&quot;Input shape: &quot;, inputs[&quot;input_ids&quot;].shape)Input shape:  torch.Size([1, 9])The sentence was encoded into 9 tokens. In case you want to know what the tokens looks like, you can just decode them back:original_input_tokens = tokenizer.convert_ids_to_tokens(inputs[&quot;input_ids&quot;][0], skip_special_tokens=False)print(&quot;Input tokens: &quot;, original_input_tokens)Input tokens:  [&#39;&lt;bos&gt;&#39;, &#39;The&#39;, &#39;Ġquick&#39;, &#39;Ġbrown&#39;, &#39;Ġfox&#39;, &#39;Ġjumps&#39;, &#39;Ġover&#39;, &#39;Ġthe&#39;, &#39;Ġlazy&#39;]As we can see, the tokenizer added the beggining of sentence &lt;bos&gt; token. The ugly Ġ represent spaces.In the notebook you can find a function clean these up a bit (I find the Ġs are really annoying):original_input_tokens = cleanup_tokens(original_input_tokens)original_input_tokens[&#39;&lt;bos&gt;&#39;, &#39;The&#39;, &#39; quick&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;]Now, let’s feed the input into the model to get the next token prediction along with all the hidden states. Fortunately, the model’s forward method provides an option to return its hidden states.# we need all the intermediate hidden stateswith torch.no_grad():    outputs = model(**inputs, output_hidden_states=True)# # print(outputs.keys())print(&quot;Logits shape: &quot;, outputs[&quot;logits&quot;].shape)Logits shape:  torch.Size([1, 9, 51200]) # (batch, sequence len, vocab size)The logits have been already projected into the vocabulary space. Hidden states on the other hand are still “raw” token representations. We’ll have one hiddent state vector for each model layer.hidden_states = outputs.hidden_statesprint(&quot;Number of model layers&quot;, len(hidden_states))print(&quot;Hidden states for first layer&quot;, hidden_states[0].shape)Number of model layers:  25Hidden states for first layer:  torch.Size([1, 9, 2048])As we see, each layer in the model produces a hidden state. Here the last dimension represents the embedding size (not the vocbulary size).By applying the language modeling head (or unembedding matrix) to the hidden state at any layer, we can generate ‘early’ logits—predictions from intermediate representations. While the model isn’t explicitly trained to produce meaningful logits at these layers, we’ll see that it naturally starts embedding token-level information along the way.We can apply the language modeling head like this:logits_at_second_layer = model.lm_head(hidden_states[2])print(&quot;Logits at second layer shape: &quot;, logits_at_second_layer.shape)Logits at second layer shape:  torch.Size([1, 9, 51200])We now want to access the hidden state at each layer, apply the language modeling head to get the logits, and finally decode the logits into tokens.for i, hidden_state in enumerate(hidden_states):    # apply the language model head to the hidden states    logits = model.lm_head(hidden_state)    # decode the logits to get the predicted token ids    predicted_token_ids = logits.argmax(-1)    # convert the token ids to tokens    predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)    predicted_tokens = cleanup_tokens(predicted_tokens)    # append the predicted tokens to the list for later    logitlens.append(predicted_tokens)    print(f&quot;Layer {i}: {predicted_tokens}&quot;)Layer 0: [&#39;-&#39;, &#39; S&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39;-&#39;, &#39; S&#39;, &#39;-&#39;]Layer 1: [&#39;ed&#39;, &#39;oret&#39;, &#39;est&#39;, &#39;ies&#39;, &#39;es&#39;, &#39;uit&#39;, &#39; the&#39;, &#39; same&#39;, &#39; double&#39;]Layer 2: [&#39;import&#39;, &#39;oret&#39;, &#39;est&#39;, &#39;ies&#39;, &#39;es&#39;, &#39;uits&#39;, &#39; time&#39;, &#39; same&#39;, &#39; part&#39;]Layer 3: [&#39;import&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;es&#39;, &#39; all&#39;, &#39; entire&#39;, &#39; man&#39;]Layer 4: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;worked&#39;, &#39; entire&#39;, &#39; man&#39;]Layer 5: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;worked&#39;, &#39; entire&#39;, &#39; man&#39;]Layer 6: [&#39; realise&#39;, &#39;orem&#39;, &#39;est&#39;, &#39;arf&#39;, &#39;es&#39;, &#39;uit&#39;, &#39;kill&#39;, &#39;ses&#39;, &#39; man&#39;]Layer 7: [&#39;iveness&#39;, &#39;orem&#39;, &#39;est&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; all&#39;, &#39; entire&#39;, &#39; brown&#39;]Layer 8: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39;ind&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 9: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 10: [&#39;iveness&#39;, &#39;orem&#39;, &#39;ness&#39;, &#39; ph&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 11: [&#39;iveness&#39;, &#39;orem&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39;ers&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 12: [&#39;iveness&#39;, &#39;oret&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 13: [&#39;ality&#39;, &#39;oret&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 14: [&#39;ality&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; ph&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 15: [&#39;iveness&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; obstacles&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 16: [&#39;import&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; into&#39;, &#39; lazy&#39;, &#39; entire&#39;, &#39; poor&#39;]Layer 17: [&#39;import&#39;, &#39;mes&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; poor&#39;]Layer 18: [&#39;import&#39;, &#39; first&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]Layer 19: [&#39; example&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;Ċ&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]Layer 20: [&#39;ĊĊ&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;s&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]Layer 21: [&#39;ing&#39;, &#39; first&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39;es&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]Layer 22: [&#39;Ċ&#39;, &#39; first&#39;, &#39; brown&#39;, &#39;Ċ&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]Layer 23: [&#39;Ċ&#39;, &#39;Ċ&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; J&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]Layer 24: [&#39;Ċ&#39;, &#39;ory&#39;, &#39; brown&#39;, &#39; fox&#39;, &#39; jumps&#39;, &#39; over&#39;, &#39; the&#39;, &#39; lazy&#39;, &#39; dog&#39;]As you observe, the predictions refine layer-by-layer, reflecting the model’s gradual understanding of the input.We can visualize the predictions with a heatmap:# create a heatmap that has a row for each list in the logitlens listimport matplotlib.pyplot as pltimport seaborn as snsimport numpy as npsns.set_theme(style=&quot;white&quot;)# just for the bkg colorintensities = np.ones((len(hidden_states), len(original_input_tokens)))# Create heatmapplt.figure(figsize=(20, 10))ax = sns.heatmap(intensities[::2],                annot=cleanup_tokens(logitlens)[::2],                fmt=&#39;&#39;,                cmap=&#39;Greys&#39;,                xticklabels=original_input_tokens,                yticklabels=list(range(len(logitlens)))[::2],                cbar=False                ).invert_yaxis()Right now, our heatmap just displays the model’s top predictions (using argmax), which is fine but a bit flat. Let’s make it more interesting by incorporating model certainty into the visualization.A good way to quantify the model’s certainity about its output is looking at the entropy of the output distribution. Let’s replace the background color of each cell with the entropy of the model when generating that token.We’ll calculate the entropy of the output distribution, using it to color the background:# aux function to compute the entropy from logitsdef entropy_from_logits(logits):    probs = torch.nn.functional.softmax(logits, dim=-1).clamp(1e-8, 1) #avoid nans    return -torch.sum(probs * torch.log(probs), dim=-1).squeeze()Now we can run the same code as before, this time we’ll also compute and store the entropies.logitlens = []entropies = []for i, hidden_state in enumerate(hidden_states):    # apply the language model head to the hidden states    logits = model.lm_head(hidden_state)    # get the entropy of the logits    entropy = entropy_from_logits(logits).float().cpu().detach().numpy()    # decode the logits to get the predicted token ids    predicted_token_ids = logits.argmax(-1)    # convert the token ids to tokens    predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_token_ids[0], skip_special_tokens=False)    predicted_tokens = cleanup_tokens(predicted_tokens)    # append the predicted tokens to the list    logitlens.append(predicted_tokens)    entropies.append(entropy)    print(f&quot;Layer {i}: {predicted_tokens}&quot;)Let’s now create a plot where each cell is colored based on the entropy.# Create figure and axisplt.figure(figsize=(20, 10))# Create heatmapax = sns.heatmap(np.stack(entropies)[::2],                annot=logitlens[::2],                fmt=&#39;&#39;,                cmap=&#39;YlGnBu&#39;,                xticklabels=original_input_tokens,                yticklabels=list(range(len(logitlens)))[::2],                ).invert_yaxis()Hope you liked this! If you have any suggestions/questios, feel free to drop me a message/email or visit my page or my twitter @devoto_alessio.">
    <meta itemprop="datePublished" content="2024-10-28T00:00:00+01:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="http://0.0.0.0:4000/LogitLens/" itemprop="url">LogitLens from scratch with Hugging Face Transformers
</a>
          </h1>
          


        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>In this short tutorial, we’ll implement LogitLens to inspect the inner representations of a pre-trained <code class="language-plaintext highlighter-rouge">Phi-1.5</code>. <a href="https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens">LogitLens</a> is a straightforward yet effective interpretability method.</p>

<p>The core idea behind it is to apply the language model’s output layer (also known as the “unembedding matrix” or “language modeling head”) to the hidden states at each layer of the transformer. This allows us to see how the model’s internal representations change as the input progresses through the network. Surprisingly, the model often acquires a significant amount of semantic understanding in the earlier layers of the transformer. By inspecting the predicted tokens at each layer, we can observe how the model’s understanding of the input evolves.</p>

<blockquote>
  <p><strong>Disclaimer</strong>: ✋ If you’re looking for advanced interpretability tools, there are plenty of powerful libraries out there. But here, we’re going back to basics and do this from scratch because it’s always cool to understand how things work under the hood.</p>
</blockquote>

<p>You can also <a href="https://drive.google.com/file/d/1nTGbjz4AK7QZqq5BgzQozqHcjpIAndCG" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

<p>We’ll use <code class="language-plaintext highlighter-rouge">Microsoft Phi-1.5 </code>here since it’s a small, open model. Feel free to swap in another Hugging Face model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">model_id</span><span class="o">=</span> <span class="s">"microsoft/phi-1.5"</span>

<span class="c1"># load the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">bfloat16</span><span class="p">).</span><span class="nb">eval</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">add_bos_token</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bos_token</span><span class="o">=</span><span class="s">'&lt;bos&gt;'</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>
<p>Downloading the model might take a while, so you better pick a small model :).
Let’s now consider an example input sentence and tokenize it.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">example</span> <span class="o">=</span> <span class="s">"The quick brown fox jumps over the lazy"</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Input shape: "</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input shape:  torch.Size([1, 9])
</code></pre></div></div>

<p>The sentence was encoded into 9 tokens. In case you want to know what the tokens looks like, you can just decode them back:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">original_input_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Input tokens: "</span><span class="p">,</span> <span class="n">original_input_tokens</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Input tokens:  ['&lt;bos&gt;', 'The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy']
</code></pre></div></div>

<p>As we can see, the tokenizer added the beggining of sentence <code class="language-plaintext highlighter-rouge">&lt;bos&gt;</code> token. The ugly <code class="language-plaintext highlighter-rouge">Ġ</code> represent spaces.</p>

<p>In the notebook you can find a function clean these up a bit (I find the <code class="language-plaintext highlighter-rouge">Ġ</code>s are really annoying):</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">original_input_tokens</span> <span class="o">=</span> <span class="n">cleanup_tokens</span><span class="p">(</span><span class="n">original_input_tokens</span><span class="p">)</span>
<span class="n">original_input_tokens</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['&lt;bos&gt;', 'The', ' quick', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy']
</code></pre></div></div>

<p>Now, let’s feed the input into the model to get the next token prediction along with all the hidden states. Fortunately, the model’s forward method provides an option to return its hidden states.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># we need all the intermediate hidden states
</span><span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># # print(outputs.keys())
</span><span class="k">print</span><span class="p">(</span><span class="s">"Logits shape: "</span><span class="p">,</span> <span class="n">outputs</span><span class="p">[</span><span class="s">"logits"</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Logits shape:  torch.Size([1, 9, 51200]) # (batch, sequence len, vocab size)
</code></pre></div></div>

<p>The logits have been already projected into the vocabulary space. Hidden states on the other hand are still “raw” token representations. We’ll have one hiddent state vector for each model layer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">hidden_states</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Number of model layers"</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Hidden states for first layer"</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of model layers:  25
Hidden states for first layer:  torch.Size([1, 9, 2048])
</code></pre></div></div>

<p>As we see, each layer in the model produces a hidden state. Here the last dimension represents the embedding size (not the vocbulary size).</p>

<p>By applying the language modeling head (or unembedding matrix) to the hidden state at any layer, we can generate ‘early’ logits—predictions from intermediate representations. While the model isn’t explicitly trained to produce meaningful logits at these layers, we’ll see that it naturally starts embedding token-level information along the way.</p>

<p>We can apply the language modeling head like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logits_at_second_layer</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Logits at second layer shape: "</span><span class="p">,</span> <span class="n">logits_at_second_layer</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Logits at second layer shape:  torch.Size([1, 9, 51200])
</code></pre></div></div>

<p>We now want to access the hidden state at each layer, apply the language modeling head to get the logits, and finally decode the logits into tokens.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">):</span>
    <span class="c1"># apply the language model head to the hidden states
</span>    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_state</span><span class="p">)</span>

    <span class="c1"># decode the logits to get the predicted token ids
</span>    <span class="n">predicted_token_ids</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># convert the token ids to tokens
</span>    <span class="n">predicted_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">predicted_token_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">predicted_tokens</span> <span class="o">=</span> <span class="n">cleanup_tokens</span><span class="p">(</span><span class="n">predicted_tokens</span><span class="p">)</span>

    <span class="c1"># append the predicted tokens to the list for later
</span>    <span class="n">logitlens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_tokens</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">predicted_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Layer 0: ['-', ' S', '-', '-', '-', '-', '-', ' S', '-']
Layer 1: ['ed', 'oret', 'est', 'ies', 'es', 'uit', ' the', ' same', ' double']
Layer 2: ['import', 'oret', 'est', 'ies', 'es', 'uits', ' time', ' same', ' part']
Layer 3: ['import', 'orem', 'est', 'arf', 'es', 'es', ' all', ' entire', ' man']
Layer 4: [' realise', 'orem', 'est', 'arf', 'es', 'uit', 'worked', ' entire', ' man']
Layer 5: [' realise', 'orem', 'est', 'arf', 'es', 'uit', 'worked', ' entire', ' man']
Layer 6: [' realise', 'orem', 'est', 'arf', 'es', 'uit', 'kill', 'ses', ' man']
Layer 7: ['iveness', 'orem', 'est', ' fox', 'es', 'ers', ' all', ' entire', ' brown']
Layer 8: ['iveness', 'orem', 'ness', ' fox', 'es', 'ers', 'ind', ' entire', ' poor']
Layer 9: ['iveness', 'orem', 'ness', ' fox', 'es', 'ers', ' obstacles', ' entire', ' poor']
Layer 10: ['iveness', 'orem', 'ness', ' ph', 'es', 'ers', ' obstacles', ' entire', ' poor']
Layer 11: ['iveness', 'orem', ' brown', ' fox', 'es', 'ers', ' obstacles', ' entire', ' poor']
Layer 12: ['iveness', 'oret', ' brown', ' fox', 'es', ' into', ' obstacles', ' entire', ' poor']
Layer 13: ['ality', 'oret', ' brown', ' fox', 'es', ' into', ' obstacles', ' entire', ' poor']
Layer 14: ['ality', 'ory', ' brown', ' ph', 'es', ' into', ' obstacles', ' entire', ' poor']
Layer 15: ['iveness', 'ory', ' brown', ' fox', 'es', ' into', ' obstacles', ' entire', ' poor']
Layer 16: ['import', 'ory', ' brown', ' fox', 'es', ' into', ' lazy', ' entire', ' poor']
Layer 17: ['import', 'mes', ' brown', ' fox', 'es', ' over', ' the', ' lazy', ' poor']
Layer 18: ['import', ' first', ' brown', ' fox', 'es', ' over', ' the', ' lazy', ' dog']
Layer 19: [' example', ' first', ' brown', 'Ċ', 'es', ' over', ' the', ' lazy', ' dog']
Layer 20: ['ĊĊ', ' first', ' brown', 's', 'es', ' over', ' the', ' lazy', ' dog']
Layer 21: ['ing', ' first', ' brown', ' fox', 'es', ' over', ' the', ' lazy', ' dog']
Layer 22: ['Ċ', ' first', ' brown', 'Ċ', ' jumps', ' over', ' the', ' lazy', ' dog']
Layer 23: ['Ċ', 'Ċ', ' brown', ' fox', ' J', ' over', ' the', ' lazy', ' dog']
Layer 24: ['Ċ', 'ory', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy', ' dog']
</code></pre></div></div>

<p>As you observe, the predictions refine layer-by-layer, reflecting the model’s gradual understanding of the input.
We can visualize the predictions with a heatmap:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create a heatmap that has a row for each list in the logitlens list
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">sns</span><span class="p">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">"white"</span><span class="p">)</span>

<span class="c1"># just for the bkg color
</span><span class="n">intensities</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_input_tokens</span><span class="p">)))</span>

<span class="c1"># Create heatmap
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">intensities</span><span class="p">[::</span><span class="mi">2</span><span class="p">],</span>
                <span class="n">annot</span><span class="o">=</span><span class="n">cleanup_tokens</span><span class="p">(</span><span class="n">logitlens</span><span class="p">)[::</span><span class="mi">2</span><span class="p">],</span>
                <span class="n">fmt</span><span class="o">=</span><span class="s">''</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="s">'Greys'</span><span class="p">,</span>
                <span class="n">xticklabels</span><span class="o">=</span><span class="n">original_input_tokens</span><span class="p">,</span>
                <span class="n">yticklabels</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">logitlens</span><span class="p">)))[::</span><span class="mi">2</span><span class="p">],</span>
                <span class="n">cbar</span><span class="o">=</span><span class="bp">False</span>
                <span class="p">).</span><span class="n">invert_yaxis</span><span class="p">()</span>

</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/alessiodevoto/alessiodevoto.github.io/refs/heads/main/assets/images/logitlens/logit_small.png" alt="png" /></p>

<p>Right now, our heatmap just displays the model’s top predictions (using <code class="language-plaintext highlighter-rouge">argmax</code>), which is fine but a bit flat. Let’s make it more interesting by incorporating model certainty into the visualization.</p>

<p>A good way to quantify the model’s certainity about its output is looking at the <a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">entropy</a> of the output distribution. Let’s replace the background color of each cell with the entropy of the model when generating that token.</p>

<p>We’ll calculate the entropy of the output distribution, using it to color the background:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># aux function to compute the entropy from logits
</span><span class="k">def</span> <span class="nf">entropy_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">):</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="mf">1e-8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1">#avoid nans
</span>    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">squeeze</span><span class="p">()</span>
</code></pre></div></div>

<p>Now we can run the same code as before, this time we’ll also compute and store the entropies.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logitlens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">entropies</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">hidden_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">):</span>
    <span class="c1"># apply the language model head to the hidden states
</span>    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_state</span><span class="p">)</span>

    <span class="c1"># get the entropy of the logits
</span>    <span class="n">entropy</span> <span class="o">=</span> <span class="n">entropy_from_logits</span><span class="p">(</span><span class="n">logits</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

    <span class="c1"># decode the logits to get the predicted token ids
</span>    <span class="n">predicted_token_ids</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># convert the token ids to tokens
</span>    <span class="n">predicted_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">predicted_token_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">predicted_tokens</span> <span class="o">=</span> <span class="n">cleanup_tokens</span><span class="p">(</span><span class="n">predicted_tokens</span><span class="p">)</span>

    <span class="c1"># append the predicted tokens to the list
</span>    <span class="n">logitlens</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">predicted_tokens</span><span class="p">)</span>
    <span class="n">entropies</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Layer </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">predicted_tokens</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s now create a plot where each cell is colored based on the entropy.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create figure and axis
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Create heatmap
</span><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">entropies</span><span class="p">)[::</span><span class="mi">2</span><span class="p">],</span>
                <span class="n">annot</span><span class="o">=</span><span class="n">logitlens</span><span class="p">[::</span><span class="mi">2</span><span class="p">],</span>
                <span class="n">fmt</span><span class="o">=</span><span class="s">''</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="s">'YlGnBu'</span><span class="p">,</span>
                <span class="n">xticklabels</span><span class="o">=</span><span class="n">original_input_tokens</span><span class="p">,</span>
                <span class="n">yticklabels</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">logitlens</span><span class="p">)))[::</span><span class="mi">2</span><span class="p">],</span>
                <span class="p">).</span><span class="n">invert_yaxis</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://raw.githubusercontent.com/alessiodevoto/alessiodevoto.github.io/refs/heads/main/assets/images/logitlens/logitlens_small.png" alt="png" /></p>

<p>Hope you liked this! If you have any suggestions/questios, feel free to drop me a message/email or visit <a href="https://alessiodevoto.github.io/">my page</a> or my twitter <a href="https://x.com/devoto_alessio">@devoto_alessio</a>.</p>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-10-28T00:00:00+01:00">October 28, 2024</time></p>

      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/yuzhaouoe" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/yu-zhao-b303482b3/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://www.instagram.com/yuzhaonlp/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-instagram" aria-hidden="true"></i> Instagram</a></li>
        
      
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 <a href="http://0.0.0.0:4000">Yu Zhao</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>









  </body>
</html>
