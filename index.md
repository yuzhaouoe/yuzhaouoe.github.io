---
layout: single
classes: wide
author_profile: true
title: ''
excerpt: "Yu Zhao's personal website"
seo_title: "Yu Zhao's personal website"
excerpt: Yu Zhao is a PhD student at the University of Edinburgh.
seo_description: Yu Zhao is a PhD student at the University of Edinburgh.

# toc: true

---

I am a 2nd year PhD student at the University of Edinburgh (start from Sept. 2023), a member of [EdinburghNLP](https://edinburghnlp.inf.ed.ac.uk/), supervised by [Pasquale Minervini](https://scholar.google.com/citations?user=9sk6CSgAAAAJ) and [Mirella Lapata](https://scholar.google.com/citations?user=j67B9Q4AAAAJ). My research interests lie in _foundation model pre-training_ and _scalable mechanism interpretability_. I am currently working to "open the black box" to enable more efficient pre-training/inference.

I will start my internship at Microsoft Research Cambridge from May to August 2025. Feel free to reach out if you’d like to meet in person!

### Selected Works

[Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering](https://arxiv.org/abs/2410.15999)  
**Yu Zhao**, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini  
NAACL 2025, <font color=orange>Oral</font>

[A Simple and Effective L2 Norm-Based Strategy for KV Cache Compression](https://arxiv.org/abs/2406.11430)  
Alessio Devoto\*, **Yu Zhao**\*, Simone Scardapane, Pasquale Minervini  
EMNLP 2024, <font color=orange>Oral</font>

[Analysing The Impact of Sequence Composition on Language Model Pre-Training](https://arxiv.org/abs/2402.13991)  
**Yu Zhao**, Yuanbin Qu, Konrad Staniszewski, Szymon Tworkowski, Wei Liu, Piotr Miłoś, Yuxiang Wu, Pasquale Minervini  
ACL 2024, <font color=orange>Oral</font>

[Analysing the Residual Stream of Language Models Under Knowledge Conflicts](https://arxiv.org/abs/2410.16090)  
**Yu Zhao**, Xiaotang Du, Giwon Hong, Aryo Pradipta Gema, Alessio Devoto, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini  
MINT @ NeurIPS 2024

[Structured Packing in LLM Training Improves Long Context Utilization](https://arxiv.org/abs/2312.17296)  
Konrad Staniszewski, Szymon Tworkowski, Sebastian Jaszczur, **Yu Zhao**, Henryk Michalewski, Łukasz Kuciński, Piotr Miłoś  
AAAI 2025, <font color=orange>Oral</font>

[Are We Done with MMLU?](https://arxiv.org/abs/2406.04127)  
Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, **Yu Zhao**, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini  
NAACL 2025

[Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression](https://arxiv.org/abs/2503.02812)  
Nathan Godey, Alessio Devoto, **Yu Zhao**, Simone Scardapane, Pasquale Minervini, Éric de la Clergerie, Benoît Sagot  
Preprint 2025

---

Check out all my publications in [Google Scholar](https://scholar.google.com/citations?user=QR0LL6gAAAAJ) or [Semantic Scholar](https://www.semanticscholar.org/author/Yu-Zhao/2155474139).

<!-- [Are We Done with MMLU?](https://arxiv.org/abs/2406.04127)  
Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, **Yu Zhao**, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini  
arXiv 2024

[The Hallucinations Leaderboard--An Open Effort to Measure Hallucinations in Large Language Models](https://arxiv.org/abs/2404.05904)  
Giwon Hong, Aryo Pradipta Gema, Rohit Saxena, Xiaotang Du, Ping Nie, **Yu Zhao**, Laura Perez-Beltrachini, Max Ryabinin, Xuanli He, Pasquale Minervini  
arXiv 2024 -->

<!-- [Structured Packing in LLM Training Improves Long Context Utilization](https://arxiv.org/abs/2312.17296)  
Konrad Staniszewski, Szymon Tworkowski, Sebastian Jaszczur, **Yu Zhao**, Henryk Michalewski, Łukasz Kuciński, Piotr Miłoś  
arXiv 2024

[An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2210.16773)  
Yuxiang Wu, **Yu Zhao**, Baotian Hu, Pasquale Minervini, Pontus Stenetorp, Sebastian Riedel  
EMNLP 2022, _Best Post Award @ NeurIPS ENLSP_ -->

<!-- [Medical Dialogue Response Generation with Pivotal Information Recalling](https://dl.acm.org/doi/abs/10.1145/3534678.3542674)  
**Yu Zhao**\*, Yunxin Li\*, Yuxiang Wu, Baotian Hu, Qingcai Chen, Xiaolong Wang, Yuxin Ding, Min Zhang  
KDD 2022

[MSDF: A General Open-Domain Multi-Skill Dialog Framework](https://link.springer.com/chapter/10.1007/978-3-030-88483-3_29)  
**Yu Zhao**\*, Xinshuo Hu\*, Yunxin Li, Baotian Hu, Dongfang Li, Sichao Chen, Xiaolong Wang  
NLPCC 2021 -->

